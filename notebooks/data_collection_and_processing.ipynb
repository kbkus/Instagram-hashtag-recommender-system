{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome # !pip install selenium\n",
    "from random import random\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve\n",
    "from uuid import uuid4\n",
    "import tensorflow as tf #!pip install tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts(hashtags, n, browser):\n",
    "    start = time.time()\n",
    "    # List to hold dictionaries with necessary identifying information for each instagram photo\n",
    "    posts = []\n",
    "    \n",
    "    # Iterate through each hashtag\n",
    "    for hashtag in hashtags:\n",
    "        # URL for that hashtag\n",
    "        url = f\"https://www.instagram.com/explore/tags/{hashtag}/\"\n",
    "        browser.get(url)\n",
    "        post = \"https://www.instagram.com/p/\"\n",
    "        \n",
    "        # empty lists to hold information from that hashtag\n",
    "        post_links = []\n",
    "        images = []\n",
    "        # Run until you have collected n images\n",
    "        while len(post_links) < n or len(images) < n:\n",
    "\n",
    "            img_src = [\n",
    "                img.get_attribute('src')\n",
    "                for img in browser.find_elements_by_css_selector('article img')\n",
    "            ]\n",
    "            links = [\n",
    "                a.get_attribute('href') for a in browser.find_elements_by_tag_name('a')\n",
    "            ]\n",
    "\n",
    "            for link in links:\n",
    "                if post in link and link not in post_links and len(post_links) < n:\n",
    "                    post_links.append(link)\n",
    "            for image in img_src:\n",
    "                if image not in images and len(images) < n:\n",
    "                    images.append(image)\n",
    "\n",
    "            scroll_down = 'window.scrollTo(0, document.body.scrollHeight);'\n",
    "            browser.execute_script(scroll_down)\n",
    "            time.sleep(1 + (random() * 5))\n",
    "\n",
    "        # Create a list of dictionaries containing the link to each post\n",
    "        # a link the the .jpg version of that image\n",
    "        # and the hashtag that was used to search it\n",
    "        posts += [{'post_link': post_links[i],\n",
    "                'image': images[i],\n",
    "                'search_hashtag': hashtag} for i in range(len(post_links))]\n",
    "    end = time.time()\n",
    "    print(f'Runtime: {end - start} to get {n*len(hashtags)} posts')\n",
    "    return posts\n",
    "\n",
    "def get_meta(posts, browser):\n",
    "    start = time.time()\n",
    "    # create a list of indices of which dictionaries need to be dropped\n",
    "    posts_update = []\n",
    "    # Iterate through each post in list\n",
    "    for post in posts:\n",
    "        # assign the url of the post\n",
    "        url = post['post_link']\n",
    "        tags = []\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            data = response.text\n",
    "            soup = BeautifulSoup(data, 'html.parser')\n",
    "            head = soup.find('head')\n",
    "            hashtags = head.find_all('meta', attrs={'property':'instapp:hashtags'})\n",
    "            for hashtag in hashtags:\n",
    "                tags.append(hashtag.get('content'))\n",
    "            \n",
    "            # check if tags is empty\n",
    "            if not tags:\n",
    "                # remove that post from the list\n",
    "                print('post had no hashtags')\n",
    "                \n",
    "            else:\n",
    "                # add entry to dictionary for that post\n",
    "                post['tags'] = tags\n",
    "                \n",
    "                # Check if post is a photo or video and only keep photos\n",
    "                try:\n",
    "                    browser.get(url)\n",
    "                    likes = int(browser.find_element_by_xpath(\"\"\"/html/body/div[1]/section/main/div/div[1]/article/div[3]/section[2]/div/div[1]/button/span\"\"\").text)\n",
    "                    # add number of likes to dictionary\n",
    "                    post['likes'] = likes\n",
    "                    # add datetime of post to dictionary\n",
    "                    posts_update.append(post)\n",
    "                    post['datetime'] = browser.find_element_by_xpath(\"\"\"/html/body/div[1]/section/main/div/div[1]/article/div[3]/div[2]/a/time\"\"\").get_attribute('datetime')\n",
    "                except:\n",
    "                    # That post was a link to a video, not an image\n",
    "                    print('post is video, not image')\n",
    "                # pause before making next request    \n",
    "                time.sleep(1 + (random() * 5))\n",
    "        except:\n",
    "            print('failed url: {}'.format(url))\n",
    "    end = time.time()\n",
    "    print(f'Runtime: {end - start} to get metadata for {len(posts_update)} posts')\n",
    "    return posts_update\n",
    "\n",
    "def get_images(posts):\n",
    "    start = time.time()\n",
    "    # rare occurance of NoneType in 'image' observation\n",
    "    # Create exception to handle those instances and remove those posts\n",
    "    posts_update = []\n",
    "    \"\"\"Download images from given url and add their names to dictionary\n",
    "    note to self: Write a way to check to make sure a folder for that hashtag category exists\"\"\"\n",
    "    for post in posts:\n",
    "        uuid = uuid4()\n",
    "        try:\n",
    "            urlretrieve(str(post['image']), f\"/Users/kacikus/Dropbox/Thinkful_Data_Science_Projects/Capstone4/images/{uuid}.jpg\")\n",
    "            name = f\"{uuid}.jpg\"\n",
    "            post['name'] = name  \n",
    "            posts_update.append(post)      \n",
    "        except:\n",
    "            print('exception encountered')\n",
    "            pass\n",
    "        \n",
    "    end = time.time()\n",
    "    print(f'Runtime: {end - start} to download {len(posts_update)} posts')\n",
    "    return posts_update\n",
    "\n",
    "def prepare_images(posts, neural_network, height=160, width=160):\n",
    "    start = time.time()\n",
    "    for post in posts:\n",
    "        path = f\"/Users/kacikus/Dropbox/Thinkful_Data_Science_Projects/Capstone4/images/{post['name']}\"\n",
    "        trash = f\"/Users/kacikus/.Trash/{post['name']}\"\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_image(img)\n",
    "        img = tf.cast(img, tf.float32)\n",
    "        img = (img/127.5) - 1\n",
    "        img = tf.image.resize(img, (height, width))\n",
    "        # reshape grayscale images to match dimensions of color images\n",
    "        if img.shape != (160, 160, 3):\n",
    "            img = tf.concat([img, img, img], axis = 2)\n",
    "        post['pic'] = img\n",
    "        # delete image to save space\n",
    "        os.remove(path)\n",
    "        # delete image from trash\n",
    "        #os.remove(trash)\n",
    "        \n",
    "        # get vector of 1280 deep features \n",
    "        img_np = np.expand_dims(img.numpy(), axis=0)\n",
    "        deep_features = neural_network.predict(img_np)[0]\n",
    "        post['deep_features'] = deep_features\n",
    "    end = time.time()\n",
    "    print(f'Runtime: {end - start} to process images and get deep features')\n",
    "    return posts\n",
    "\n",
    "def get_data(hashtags, n, browser):\n",
    "    posts = get_posts(hashtags, n, browser)\n",
    "    posts = get_meta(posts, browser)\n",
    "    return pd.DataFrame(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Neural Network\n",
    "img_shape = (160, 160, 3)\n",
    "\n",
    "# create the base model from the pre-trained model MobileNet V2\n",
    "base_model = MobileNetV2(input_shape = img_shape, include_top = False,\n",
    "                        weights = 'imagenet')\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "neural_network = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    global_average_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(posts)\n",
    "df1.to_pickle('/Users/kacikus/Dropbox/Thinkful_Data_Science_Projects/Capstone4/processed_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect new data\n",
    "1. Adjust hashtags\n",
    "2. Change 'n' to equal how many images per hashtag you want to collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 5192.160176038742 to get 2000 posts\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post is video, not image\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "post had no hashtags\n",
      "Runtime: 13021.98708987236 to get metadata for 1576 posts\n"
     ]
    }
   ],
   "source": [
    "# collect data\n",
    "hashtags = ['fitness','food','nature','mechanicalkeyboard']\n",
    "browser = Chrome(executable_path='/Users/kacikus/Dropbox/Thinkful_Data_Science_Projects/Capstone4/chromedriver 2')\n",
    "df = get_data(hashtags,n = 500, browser)\n",
    "#df = pd.concat([df1,df2]).drop(columns=['name']).drop_duplicates(subset='post_link').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/Users/kacikus/Dropbox/Thinkful_Data_Science_Projects/Capstone4/data.csv')\n",
    "# convert dataframe back to list of dictionaries\n",
    "posts = [df.iloc[i].to_dict() for i in range(len(df))]\n",
    "# split up into lists of 50 entries at a time or fewer\n",
    "chunks = [posts[x:x+100] for x in range(0, len(posts), 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 7.024293899536133 to download 100 posts\n",
      "Runtime: 9.778025150299072 to process images and get deep features\n",
      "Runtime: 7.958451986312866 to download 100 posts\n",
      "Runtime: 8.393651962280273 to process images and get deep features\n",
      "Runtime: 5.816488027572632 to download 100 posts\n",
      "Runtime: 8.176470756530762 to process images and get deep features\n",
      "Runtime: 6.480806112289429 to download 100 posts\n",
      "Runtime: 7.971073150634766 to process images and get deep features\n",
      "Runtime: 6.768360137939453 to download 100 posts\n",
      "Runtime: 8.108715057373047 to process images and get deep features\n",
      "Runtime: 6.763459205627441 to download 100 posts\n",
      "Runtime: 8.102815866470337 to process images and get deep features\n",
      "Runtime: 6.6255106925964355 to download 100 posts\n",
      "Runtime: 8.04637622833252 to process images and get deep features\n",
      "Runtime: 8.78427004814148 to download 100 posts\n",
      "Runtime: 7.874860048294067 to process images and get deep features\n",
      "Runtime: 7.53360915184021 to download 100 posts\n",
      "Runtime: 7.543951034545898 to process images and get deep features\n",
      "Runtime: 6.801548957824707 to download 100 posts\n",
      "Runtime: 7.722674369812012 to process images and get deep features\n",
      "Runtime: 6.772672891616821 to download 100 posts\n",
      "Runtime: 8.050122022628784 to process images and get deep features\n",
      "Runtime: 7.482218027114868 to download 100 posts\n",
      "Runtime: 7.727520227432251 to process images and get deep features\n",
      "exception encountered\n",
      "Runtime: 5.922958135604858 to download 99 posts\n",
      "Runtime: 7.646336078643799 to process images and get deep features\n",
      "Runtime: 6.50683856010437 to download 100 posts\n",
      "Runtime: 7.78296971321106 to process images and get deep features\n",
      "Runtime: 6.7536163330078125 to download 100 posts\n",
      "Runtime: 7.9102232456207275 to process images and get deep features\n",
      "Runtime: 4.496314764022827 to download 76 posts\n",
      "Runtime: 5.987046241760254 to process images and get deep features\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    chunk = get_images(chunk)\n",
    "    chunk = prepare_images(chunk, neural_network = neural_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join chunks into single list again\n",
    "posts = [post for chunk in chunks for post in chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous data\n",
    "df_prev = pd.read_pickle('/Users/kacikus/Dropbox/Thinkful_Data_Science_Projects/Capstone4/processed_data.pkl')\n",
    "# convert posts to df\n",
    "df_new = pd.DataFrame(posts).drop(columns='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3748 entries, 0 to 3747\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   post_link       3748 non-null   object\n",
      " 1   image           3748 non-null   object\n",
      " 2   search_hashtag  3748 non-null   object\n",
      " 3   tags            3748 non-null   object\n",
      " 4   likes           3748 non-null   int64 \n",
      " 5   datetime        3748 non-null   object\n",
      " 6   pic             3748 non-null   object\n",
      " 7   deep_features   3748 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 234.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_prev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1576 entries, 0 to 1575\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   post_link       1576 non-null   object\n",
      " 1   image           1575 non-null   object\n",
      " 2   search_hashtag  1576 non-null   object\n",
      " 3   tags            1576 non-null   object\n",
      " 4   likes           1576 non-null   int64 \n",
      " 5   datetime        1576 non-null   object\n",
      " 6   pic             1575 non-null   object\n",
      " 7   deep_features   1575 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 98.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert posts back to dataframe\n",
    "# Some of the posts still had the unecessary 'Unnamed' colunn, so drop that as well\n",
    "# drop name column since we have deleted the pictures\n",
    "df = pd.concat([df_prev, df_new]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5324 entries, 0 to 5323\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   post_link       5324 non-null   object\n",
      " 1   image           5323 non-null   object\n",
      " 2   search_hashtag  5324 non-null   object\n",
      " 3   tags            5324 non-null   object\n",
      " 4   likes           5324 non-null   int64 \n",
      " 5   datetime        5324 non-null   object\n",
      " 6   pic             5323 non-null   object\n",
      " 7   deep_features   5323 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 332.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pickle\n",
    "name = 'update_processed_data.pkl'\n",
    "df.to_pickle(f'/Users/kacikus/Dropbox/Thinkful_Data_Science_Projects/Capstone4/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ['cats_of_instagram', 'catstagramcat', 'admire...\n",
       "1       ['catsofinstagram', 'cats_of_instagram', 'catl...\n",
       "2       ['blackandwhitecatsofinstagram', 'petsofinstag...\n",
       "3       ['cats', 'cattos', 'cats_of_instagram', 'sadca...\n",
       "4       ['miaou', 'catlife', 'queenpika', 'cat', 'chat...\n",
       "                              ...                        \n",
       "3743    ['tomandjame', 'future', 'amsterdamdanceevent'...\n",
       "3744    ['少女前線', 'cute', 'girlsfrontline', 'animegirl'...\n",
       "3745    ['codingbootcamp', 'startuplife', 'dev', 'codi...\n",
       "3746    ['sea', 'vendée', 'departementvendee', 'boat',...\n",
       "3747    ['computers', 'puzzle', 'puzzles', 'technology...\n",
       "Name: tags, Length: 3748, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
